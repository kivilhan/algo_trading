{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import numpy as np\n",
    "import data_pipes\n",
    "\n",
    "df_path = \"processed_aapl_data.csv\"\n",
    "data = data_pipes.process_df(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class georgia_0(nn.Module):\n",
    "    def __init__(self, win_past=20, features=19, dropout_rate=0.4):\n",
    "        super().__init__()\n",
    "        self.flat0 = nn.Flatten()\n",
    "\n",
    "        self.hidden0 = nn.Linear(features*win_past, 128)\n",
    "        self.act0 = nn.ReLU()\n",
    "        self.dropout0 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.hidden1 = nn.Linear(128, 128)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.hidden2 = nn.Linear(128, 128)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.output = nn.Linear(128, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.flat0(x)\n",
    "        x = self.dropout0(self.act0(self.hidden0(x)))\n",
    "        x = self.dropout1(self.act1(self.hidden1(x)))\n",
    "        x = self.dropout2(self.act2(self.hidden2(x)))\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class georgia_1(nn.Module):\n",
    "    def __init__(self, config, win_past=20, features=19):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Flatten())\n",
    "\n",
    "        for idx in range(len(config['neurons'])):\n",
    "            if config['activations'][idx] == 'relu':\n",
    "                activation = nn.ReLU()\n",
    "            elif config['activations'][idx] == 'selu':\n",
    "                activation = nn.SELU()\n",
    "            elif config['activations'][idx] == 'sigmoid':\n",
    "                activation = nn.Sigmoid()\n",
    "            elif config['activations'][idx] == 'none':\n",
    "                activation = \"none\"\n",
    "            else:\n",
    "                raise ValueError(f\"Unrecognized activation function at index {idx}: {activations[idx]}\")\n",
    "\n",
    "            if idx == 0:\n",
    "                self.layers.append(nn.Linear(features*win_past, config['neurons'][idx]))\n",
    "            else:\n",
    "                self.layers.append(nn.Linear(config['neurons'][idx - 1], config['neurons'][idx]))\n",
    "\n",
    "            if activation != 'none':\n",
    "                self.layers.append(activation)\n",
    "\n",
    "            self.layers.append(nn.Dropout(config['dropouts'][idx]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_model_config():\n",
    "    num_layers = random.randint(1, 10)  # Random number of layers between 1 and 10\n",
    "    neurons = [random.randint(4, 512) for _ in range(num_layers - 1)] + [1]  # Last neuron always 1\n",
    "    activations = [random.choice(['relu', 'selu', 'sigmoid', 'none']) for _ in range(num_layers)]\n",
    "    dropouts = [round(random.uniform(0.0, 0.5), 2) for _ in range(num_layers - 1)] + [0.0]  # Last dropout is 0\n",
    "\n",
    "    return {\n",
    "        \"neurons\": neurons,\n",
    "        \"activations\": activations,\n",
    "        \"dropouts\": dropouts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, t = 4.05, score = 0.1727, best score = 0.1727\n",
      "Iteration 1, t = 4.97, score = 0.1709, best score = 0.1709\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     33\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mtrain_loop(x_t, y_t, model, loss_fn, optimizer, batch_size)\n\u001b[1;32m---> 34\u001b[0m     test_loss_new \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     best_test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(best_test_loss, test_loss_new)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# if test_loss_new < test_loss or epoch == epochs - 1:\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m#     print(f\"---------- Epoch {epoch + 1} ----------\")\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m#     print(f\"loss: {loss:1.4f}, test loss: {test_loss_new:1.4f}\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m#     print(f\"Checkpoint: test loss = {test_loss:1.4f} <---------------\")\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#     torch.save(model.state_dict(), r\"models/hanzo_0\")\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ilhan\\Desktop\\code\\algo_trading\\georgia_DQN\\torch_ops.py:43\u001b[0m, in \u001b[0;36mtest_loop\u001b[1;34m(x, y, model, loss_fn, batch_size)\u001b[0m\n\u001b[0;32m     41\u001b[0m         batch_start, batch_end \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;241m*\u001b[39m batch_size, (batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size\n\u001b[0;32m     42\u001b[0m         x_batch, y_batch \u001b[38;5;241m=\u001b[39m x[batch_start:batch_end], y[batch_start:batch_end]\n\u001b[1;32m---> 43\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m         test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(pred, y_batch)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     46\u001b[0m test_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m num_batches\n",
      "File \u001b[1;32mc:\\Users\\ilhan\\AppData\\Local\\Programs\\Python\\envs\\autoreq312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ilhan\\AppData\\Local\\Programs\\Python\\envs\\autoreq312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 60\u001b[0m, in \u001b[0;36mgeorgia_1.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 60\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\ilhan\\AppData\\Local\\Programs\\Python\\envs\\autoreq312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ilhan\\AppData\\Local\\Programs\\Python\\envs\\autoreq312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ilhan\\AppData\\Local\\Programs\\Python\\envs\\autoreq312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch_ops as ops\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x, y = data[\"x\"], data[\"y\"]\n",
    "v_split = 0.7\n",
    "v_cutoff = int(len(x)*v_split)\n",
    "x_t = torch.tensor(x[:v_cutoff], dtype=torch.float32).to(device)\n",
    "x_v = torch.tensor(x[v_cutoff:], dtype=torch.float32).to(device)\n",
    "y_t = torch.tensor(y[:v_cutoff], dtype=torch.float32).to(device)\n",
    "y_v = torch.tensor(y[v_cutoff:], dtype=torch.float32).to(device)\n",
    "\n",
    "win_past, features = x.shape[1], x.shape[2]\n",
    "epochs, batch_size, lr, l2_decay = 250, 32, 1e-5, 2e-5\n",
    "best_score = 1\n",
    "scores = []\n",
    "for iteration in range(5000):\n",
    "    model_config = random_model_config()\n",
    "    model = georgia_1(model_config, win_past=win_past, features=features).to(device)\n",
    "    loss_fn = nn.L1Loss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr, weight_decay=l2_decay)\n",
    "\n",
    "    # loss = ops.test_loop(x_t, y_t, model, loss_fn, batch_size)\n",
    "    # test_loss = ops.test_loop(x_v, y_v, model, loss_fn, batch_size)\n",
    "    # print(\"---------- Epoch 0 ----------\")\n",
    "    # print(f\"loss: {loss:1.4f}, test loss: {test_loss:1.4f}\")\n",
    "\n",
    "    best_test_loss = 999\n",
    "    t0 = time.perf_counter()\n",
    "    for epoch in range(epochs):\n",
    "        loss = ops.train_loop(x_t, y_t, model, loss_fn, optimizer, batch_size)\n",
    "        test_loss_new = ops.test_loop(x_v, y_v, model, loss_fn, batch_size)\n",
    "        best_test_loss = min(best_test_loss, test_loss_new)\n",
    "\n",
    "\n",
    "        # if test_loss_new < test_loss or epoch == epochs - 1:\n",
    "        #     print(f\"---------- Epoch {epoch + 1} ----------\")\n",
    "        #     print(f\"loss: {loss:1.4f}, test loss: {test_loss_new:1.4f}\")\n",
    "        \n",
    "        # improvement = test_loss_new < test_loss\n",
    "        # if improvement:\n",
    "        #     test_loss = test_loss_new\n",
    "        #     print(f\"Checkpoint: test loss = {test_loss:1.4f} <---------------\")\n",
    "        #     torch.save(model.state_dict(), r\"models/hanzo_0\")\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    model_config['score'] = best_test_loss\n",
    "    scores.append(model_config)\n",
    "    best_score = min(best_score, best_test_loss)\n",
    "\n",
    "    print(f\"Iteration {iteration}, t = {t1 - t0:1.2f}, score = {best_test_loss:1.4f}, best score = {best_score:1.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000002187F7B82E0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoreq312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
