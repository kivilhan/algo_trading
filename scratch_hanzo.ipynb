{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants\n",
    "import yfinance as yf\n",
    "\n",
    "# Get symbols from constants file\n",
    "lines = constants.sa_str.splitlines()\n",
    "symbols = [line.split(\"\\t\")[1] for line in lines][:100]\n",
    "\n",
    "# Download data\n",
    "df = yf.download(symbols + [\"SPY\"], period=\"1y\", interval=\"1h\", ignore_tz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_pipes\n",
    "\n",
    "hanzo_data = data_pipes.hanzo_df_array(symbols, df)\n",
    "hanzo_data['y'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "class hanzo_0(nn.Module):\n",
    "    def __init__(self, hist):\n",
    "        super().__init__()\n",
    "        self.flat0 = nn.Flatten()\n",
    "        self.hidden0 = nn.Linear(hist*2, hist)\n",
    "        self.act0 = nn.Tanh()\n",
    "        self.hidden1 = nn.Linear(hist, hist)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.hidden2 = nn.Linear(hist, 1)\n",
    "        self.act2 = nn.Tanh()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.flat0(x)\n",
    "        x = self.act0(self.hidden0(x))\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "class hanzo_1(nn.Module):\n",
    "    def __init__(self, hist, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.flat0 = nn.Flatten(start_dim=1)\n",
    "        self.hidden0 = nn.Linear(hist * 2, hist)\n",
    "        self.act0 = nn.ReLU()\n",
    "        self.dropout0 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.hidden1 = nn.Linear(hist, hist)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.hidden2 = nn.Linear(hist, 1)\n",
    "        self.act2 = nn.Tanh()  # Keeping tanh for the output since it's likely regression\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flat0(x)\n",
    "        x = self.dropout0(self.act0(self.hidden0(x)))\n",
    "        x = self.dropout1(self.act1(self.hidden1(x)))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch_ops as ops\n",
    "from copy import deepcopy\n",
    "\n",
    "hist = 10\n",
    "epochs, batch_size, lr, l2_decay = 200, 32, 1e-4, 1e-5\n",
    "model = hanzo_1(hist=hist)\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr, weight_decay=l2_decay)\n",
    "\n",
    "period = 70\n",
    "x = torch.tensor(hanzo_data[\"x\"], dtype=torch.float32)\n",
    "y = torch.tensor(hanzo_data[\"y\"], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Epoch 1 ----------\n",
      "loss: 0.1018, test loss: 0.3153\n",
      "Checkpoint: test loss = 0.3153 <---------------\n",
      "---------- Epoch 2 ----------\n",
      "loss: 0.0896, test loss: 0.3153\n",
      "Checkpoint: test loss = 0.3153 <---------------\n",
      "---------- Epoch 3 ----------\n",
      "loss: 0.0872, test loss: 0.3153\n",
      "Checkpoint: test loss = 0.3153 <---------------\n",
      "---------- Epoch 4 ----------\n",
      "loss: 0.1046, test loss: 0.3153\n",
      "Checkpoint: test loss = 0.3153 <---------------\n",
      "---------- Epoch 71 ----------\n",
      "loss: 0.0889, test loss: 0.3153\n",
      "Checkpoint: test loss = 0.3153 <---------------\n",
      "---------- Epoch 72 ----------\n",
      "loss: 0.0950, test loss: 0.3153\n",
      "Checkpoint: test loss = 0.3153 <---------------\n",
      "---------- Epoch 73 ----------\n",
      "loss: 0.0879, test loss: 0.3152\n",
      "Checkpoint: test loss = 0.3152 <---------------\n",
      "---------- Epoch 74 ----------\n",
      "loss: 0.1026, test loss: 0.3152\n",
      "Checkpoint: test loss = 0.3152 <---------------\n",
      "---------- Epoch 75 ----------\n",
      "loss: 0.1002, test loss: 0.3152\n",
      "Checkpoint: test loss = 0.3152 <---------------\n",
      "---------- Epoch 76 ----------\n",
      "loss: 0.0724, test loss: 0.3152\n",
      "Checkpoint: test loss = 0.3152 <---------------\n",
      "---------- Epoch 77 ----------\n",
      "loss: 0.1027, test loss: 0.3152\n",
      "Checkpoint: test loss = 0.3152 <---------------\n",
      "---------- Epoch 78 ----------\n",
      "loss: 0.0959, test loss: 0.3152\n",
      "Checkpoint: test loss = 0.3152 <---------------\n",
      "---------- Epoch 79 ----------\n",
      "loss: 0.0833, test loss: 0.3151\n",
      "Checkpoint: test loss = 0.3151 <---------------\n",
      "---------- Epoch 80 ----------\n",
      "loss: 0.1047, test loss: 0.3151\n",
      "Checkpoint: test loss = 0.3151 <---------------\n",
      "---------- Epoch 81 ----------\n",
      "loss: 0.0946, test loss: 0.3151\n",
      "Checkpoint: test loss = 0.3151 <---------------\n",
      "---------- Epoch 82 ----------\n",
      "loss: 0.0900, test loss: 0.3151\n",
      "Checkpoint: test loss = 0.3151 <---------------\n",
      "---------- Epoch 83 ----------\n",
      "loss: 0.0961, test loss: 0.3151\n",
      "Checkpoint: test loss = 0.3151 <---------------\n",
      "---------- Epoch 84 ----------\n",
      "loss: 0.0866, test loss: 0.3150\n",
      "Checkpoint: test loss = 0.3150 <---------------\n",
      "---------- Epoch 85 ----------\n",
      "loss: 0.1011, test loss: 0.3150\n",
      "Checkpoint: test loss = 0.3150 <---------------\n",
      "---------- Epoch 86 ----------\n",
      "loss: 0.0952, test loss: 0.3150\n",
      "Checkpoint: test loss = 0.3150 <---------------\n",
      "---------- Epoch 87 ----------\n",
      "loss: 0.0838, test loss: 0.3150\n",
      "Checkpoint: test loss = 0.3150 <---------------\n",
      "---------- Epoch 88 ----------\n",
      "loss: 0.0786, test loss: 0.3150\n",
      "Checkpoint: test loss = 0.3150 <---------------\n",
      "---------- Epoch 89 ----------\n",
      "loss: 0.0903, test loss: 0.3149\n",
      "Checkpoint: test loss = 0.3149 <---------------\n",
      "---------- Epoch 90 ----------\n",
      "loss: 0.0874, test loss: 0.3149\n",
      "Checkpoint: test loss = 0.3149 <---------------\n",
      "---------- Epoch 91 ----------\n",
      "loss: 0.0871, test loss: 0.3149\n",
      "Checkpoint: test loss = 0.3149 <---------------\n",
      "---------- Epoch 92 ----------\n",
      "loss: 0.0895, test loss: 0.3149\n",
      "Checkpoint: test loss = 0.3149 <---------------\n",
      "---------- Epoch 93 ----------\n",
      "loss: 0.0976, test loss: 0.3149\n",
      "Checkpoint: test loss = 0.3149 <---------------\n",
      "---------- Epoch 94 ----------\n",
      "loss: 0.0975, test loss: 0.3149\n",
      "Checkpoint: test loss = 0.3149 <---------------\n",
      "---------- Epoch 95 ----------\n",
      "loss: 0.0928, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 96 ----------\n",
      "loss: 0.0904, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 97 ----------\n",
      "loss: 0.0950, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 98 ----------\n",
      "loss: 0.0897, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 99 ----------\n",
      "loss: 0.0982, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 100 ----------\n",
      "loss: 0.0894, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 101 ----------\n",
      "loss: 0.1036, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 102 ----------\n",
      "loss: 0.0956, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 103 ----------\n",
      "loss: 0.0888, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 104 ----------\n",
      "loss: 0.0892, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 105 ----------\n",
      "loss: 0.0852, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 106 ----------\n",
      "loss: 0.0951, test loss: 0.3148\n",
      "Checkpoint: test loss = 0.3148 <---------------\n",
      "---------- Epoch 200 ----------\n",
      "loss: 0.0981, test loss: 0.3149\n"
     ]
    }
   ],
   "source": [
    "t = period\n",
    "# for t in range(period, len(x)):\n",
    "x_t = x[t - period:t]\n",
    "x_v = x[t - 1:t]\n",
    "x_t_flat = torch.concatenate([x_t[:, i] for i in range(x_t.shape[1])])\n",
    "x_v_flat = torch.concatenate([x_v[:, i] for i in range(x_v.shape[1])])\n",
    "\n",
    "y_t = y[t - period:t]\n",
    "y_v = y[t - 1:t]\n",
    "y_t_flat = torch.concatenate([y_t[:, i] for i in range(y_t.shape[1])])\n",
    "y_v_flat = torch.concatenate([y_v[:, i] for i in range(y_v.shape[1])])\n",
    "\n",
    "test_loss = 999\n",
    "for epoch in range(epochs):\n",
    "    loss = ops.train_loop(x_t_flat, y_t_flat, model, loss_fn, optimizer, batch_size)\n",
    "    test_loss_new = ops.test_loop(x_v_flat, y_v_flat, model, loss_fn, batch_size)\n",
    "\n",
    "    if test_loss_new < test_loss or epoch == epochs - 1:\n",
    "        print(f\"---------- Epoch {epoch + 1} ----------\")\n",
    "        print(f\"loss: {loss:1.4f}, test loss: {test_loss_new:1.4f}\")\n",
    "        \n",
    "    if test_loss_new < test_loss:\n",
    "        test_loss = test_loss_new\n",
    "        print(f\"Checkpoint: test loss = {test_loss:1.4f} <---------------\")\n",
    "        state_dict_save = deepcopy(model.state_dict())\n",
    "        torch.save(model.state_dict(), r\"models/hanzo_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7070, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "t = period\n",
    "x_t = x[t - period:t]\n",
    "x_v = x[t - 1:t]\n",
    "x_t_flat = torch.concatenate([x_t[:, i] for i in range(x_t.shape[1])])\n",
    "x_v_flat = torch.concatenate([x_v[:, i] for i in range(x_v.shape[1])])\n",
    "\n",
    "y_t = y[t - period:t]\n",
    "y_v = y[t - 1:t]\n",
    "y_t_flat = torch.concatenate([y_t[:, i] for i in range(y_t.shape[1])])\n",
    "y_v_flat = torch.concatenate([y_v[:, i] for i in range(y_v.shape[1])])\n",
    "print(x_t_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7070, 10, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoreq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
